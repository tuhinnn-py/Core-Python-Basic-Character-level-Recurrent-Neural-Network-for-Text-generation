{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nclass RNN:\n    \n    def __init__(self,n_neurons,vocab_size):\n        self.wh=np.random.randn(n_neurons,n_neurons)*0.01\n        self.wx=np.random.randn(n_neurons,vocab_size)*0.01\n        self.wy=np.random.randn(vocab_size,n_neurons)*0.01\n        self.by=np.zeros((vocab_size,1))\n        self.bx=np.zeros((n_neurons,1))\n        \n    def forward_pass(self,data,batch_size,vocab_size,epochs,n_neurons,learning_rate,indefinite=False):\n        mwh,mwx,mwy=np.zeros_like(self.wh),np.zeros_like(self.wx),np.zeros_like(self.wy)\n        mbx,mby=np.zeros_like(self.bx),np.zeros_like(self.by)\n        smooth_loss=np.log(vocab_size)*batch_size\n        n,p=0,0\n        while(indefinite or n<epochs):\n            if p+batch_size+1>=len(data) or n==0:\n                hprev=np.zeros((n_neurons,1))\n                p=0\n            inputs=[char_to_ix[c] for c in data[p:p+batch_size]]\n            targets=[char_to_ix[c] for c in data[p+1:p+batch_size+1]]\n            \n            if n%100==0:\n                txt=self.predict(vocab_size,inputs[0],hprev,50)\n                str_predict=''.join([ix_to_char[i] for i in txt])\n                print('----\\n %s \\n-----'%(str_predict))\n            \n            loss,dwx,dwh,dbx,dwy,dby,hprev=self.lossFun(vocab_size,inputs,targets,hprev)\n            smooth_loss=0.999*smooth_loss+0.001*loss\n            \n            if n%100==0:\n                print('Epoch:%d,Loss=%6f'%(n,loss))\n            \n            for param,dparam,mem in zip([self.wx,self.wy,self.wh,self.bx,self.by],[dwx,dwy,dwh,dbx,dby],[mwx,mwy,mwh,mbx,mby]):\n                mem+=dparam*dparam\n                param+=-learning_rate*dparam/(np.sqrt(mem)+1e-7)\n            \n            p+=batch_size\n            n+=1\n                \n    def lossFun(self,vocab_size,inputs,targets,hprev):\n        X,H,P,Y={},{},{},{}\n        loss=0.0\n        H[-1]=np.copy(hprev)\n        for t in range(len(inputs)):\n            X[t]=np.zeros((vocab_size,1))\n            X[t][inputs[t]]=1\n            H[t]=np.tanh(np.dot(self.wx,X[t])+np.dot(self.wh,H[t-1])+self.bx)\n            Y[t]=np.dot(self.wy,H[t])+self.by\n            \n            P[t]=np.exp(Y[t])/np.sum(np.exp(Y[t]))\n            loss+=-np.log(P[t][targets[t],0])\n        \n        dwx,dwh,dwy=np.zeros_like(self.wx),np.zeros_like(self.wh),np.zeros_like(self.wy)\n        dbx,dby=np.zeros_like(self.bx),np.zeros_like(self.by)\n        dhnext=np.zeros_like(H[0])\n        \n        for t in reversed(range(len(inputs))):\n            dy=np.copy(P[t])\n            dy[targets[t]]-=1\n            \n            dby+=np.copy(dy)\n            dwy+=np.dot(dy,H[t].T)\n            dh=np.dot(self.wy.T,dy)+dhnext\n            \n            dhraw=(1-H[t]*H[t])*dh\n            dbx+=dhraw\n            dwh+=np.dot(dhraw,H[t-1].T)\n            dwx+=np.dot(dhraw,X[t].T)\n            dhnext=np.dot(self.wh.T,dhraw)\n        \n        for param in [dwx,dwy,dby,dbx,dwh]:\n            np.clip(param,-5,5,out=param)\n        return loss,dwx,dwh,dbx,dwy,dby,H[len(inputs)-1]\n        \n    def predict(self,vocab_size,seed_ix,h,n):\n        ix=[]\n        X=np.zeros((vocab_size,1))\n        X[seed_ix]=1\n        for t in range(n):\n            h=np.tanh(np.dot(self.wx,X)+np.dot(self.wh,h)+self.bx)\n            Y=np.dot(self.wy,h)+self.by\n            P=np.exp(Y)/np.sum(np.exp(Y))\n            idx=np.random.choice(range(vocab_size),p=P.ravel())\n            X=np.zeros((vocab_size,1))\n            X[idx]=1\n            ix.append(idx)     \n        return ix\n    \ndirname,_,filename=list(os.walk('/kaggle/input'))[1]\ndata=docx2txt.process(os.path.join(dirname,filename[0]))\nX=set(data)\ndata_size,vocab_size=len(data),len(X)\n\nchar_to_ix={c:i for i,c in enumerate(X)}\nix_to_char={i:c for i,c in enumerate(X)}\n\nepochs,n_neurons,batch_size,learning_rate=30000,512,25,1e-1\nseed_ix,prediction_size=char_to_ix['#'],25\n\nmodel=RNN(n_neurons,vocab_size)\nmodel.forward_pass(data,batch_size,vocab_size,epochs,n_neurons,learning_rate,False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seeds=[char_to_ix[c] for c in X]\nh=np.zeros((n_neurons,1))\nfor seed_ix in seeds:\n    txt=model.predict(vocab_size,seed_ix,h,100)\n    print(ix_to_char[seed_ix]+''.join([ix_to_char[i] for i in txt]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install docx2txt","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}